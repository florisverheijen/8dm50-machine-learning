{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "The `pandas` library allows the user several data structures for different data manipulation tasks:\n",
    "1. Data storage through its `Series` and `DataFrame` data structures.\n",
    "2. Data filtering using multiple methods from the package.\n",
    "3. Reading data from many different file formats such as `csv`, `txt`, `xlsx`, ...\n",
    "\n",
    "Below we provide a brief overview of the `pandas` functionalities needed for these exercises. The complete documentation can be found on the [`pandas` website](https://pandas.pydata.org/).\n",
    "\n",
    "## Pandas data structures\n",
    "\n",
    "### Series\n",
    "The Pandas Series data structure is similar to a one-dimensional array. It can store any type of data. The values are mutable but the size not.\n",
    "\n",
    "To create `Series`, we call the `pd.Series()` method and pass an array. A `Series` may also be created from a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "first_series = pd.Series([1,10,100,1000])\n",
    "\n",
    "print(first_series)\n",
    "\n",
    "teams = np.array(['PSV','Ajax','Feyenoord','Twente'])\n",
    "second_series = pd.Series(teams)\n",
    "\n",
    "print('\\n')\n",
    "print(second_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "One can think of a `DataFrame` as a table with rows and columns (2D structure). The columns can be of a different type (as opposed to `numpy` arrays) and the size of the `DataFrame` is mutable.\n",
    "\n",
    "To create `DataFrame`, we call the `pd.DataFrame()` method and we can create it from scratch or we can convert a numpy array or a list into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from scratch\n",
    "first_dataframe = pd.DataFrame({\n",
    "    \"Position\": [1, 2, 3, 4],\n",
    "    \"Team\": ['PSV','Ajax','Feyenoord','Twente'],\n",
    "    \"GF\": [80, 75, 75, 70],\n",
    "    \"GA\": [30, 25, 40, 60],\n",
    "    \"Points\": [79, 78, 70, 66]\n",
    "})\n",
    "\n",
    "print(\"From scratch: \\n {} \\n\".format(first_dataframe))\n",
    "\n",
    "# DataFrme from a list\n",
    "data = [[1, 2, 3, 4], ['PSV','Ajax','Feyenoord','Twente'], \n",
    "        [80, 75, 75, 70], [30, 25, 40, 60], [79, 78, 70, 66]]\n",
    "columns = [\"Position\", \"Team\", \"GF\", \"GA\", \"Points\"]\n",
    "\n",
    "second_dataframe = pd.DataFrame(data, index=columns)\n",
    "\n",
    "print(\"From list: \\n {} \\n\".format(second_dataframe.T)) # the '.T' operator is explained later on\n",
    "\n",
    "# DataFrame from numpy array\n",
    "data = np.array([[1, 2, 3, 4], ['PSV','Ajax','Feyenoord','Twente'], \n",
    "                 [80, 75, 75, 70], [30, 25, 40, 60], [79, 78, 70, 66]])\n",
    "columns = [\"Position\", \"Team\", \"GF\", \"GA\", \"Points\"]\n",
    "\n",
    "third_dataframe = pd.DataFrame(data.T, columns=columns)\n",
    "\n",
    "print(\"From numpy array: \\n {} \\n\".format(third_dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame attributes\n",
    "This section gives a quick overview of some of the `pandas.DataFrame` attributes such as `T`, `index`, `columns`, `iloc`, `loc`, `shape` and `values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the index and columns\n",
    "print(third_dataframe.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index makes reference to the row labels\n",
    "print(third_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns makes reference to the column labels\n",
    "print(third_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc allows to access the index by integer-location (e.g. all team names, which are in the second columm)\n",
    "print(third_dataframe.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc allows to access the index by label(s)-location (e.g. all team names, which are in the \"Team\" columm)\n",
    "print(third_dataframe.loc[0, 'Team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape returns a tuple with the DataFrame dimension, similar to numpy\n",
    "print(third_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values return a Numpy representation of the DataFrame data\n",
    "print(third_dataframe.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame methods\n",
    "This section gives a quick overview of some of the `pandas.DataFrame` methods such as `head`, `describe`, `concat`, `groupby`,`rename`, `filter`, `drop` and `isna`. To import data from CSV or MS Excel files, we can make use of `read_csv` and `read_excel`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first few rows in your dataset with head()\n",
    "print(third_dataframe.head()) # In this case, it is not very useful because we don't have thousands of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the summary statistics of the DataFrame with describe()\n",
    "print(third_dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate (join) DataFrame objects using concat()\n",
    "\n",
    "# first, we will split the above DataFrame in two different ones\n",
    "df_a = third_dataframe.loc[[0,1],:]\n",
    "df_b = third_dataframe.loc[[2,3],:]\n",
    "\n",
    "print(df_a)\n",
    "print('\\n')\n",
    "\n",
    "print(df_b)\n",
    "print('\\n')\n",
    "\n",
    "# now, we concatenate both datasets\n",
    "df = pd.concat([df_a, df_b])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by certain variable via groupby()\n",
    "# here, we have grouped the data by goals for, which in this case is 75\n",
    "\n",
    "group = df.groupby('GF')\n",
    "\n",
    "print(group.get_group('75'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename() helps you change the column or index names\n",
    "print(df.rename(columns={'Position':'Pos','Team':'Club'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a subset of rows or columns of your dataset according to labels via filter()\n",
    "# here, items refer to the variable names: 'Team' and 'Points'; to select columns, we specify axis=1\n",
    "print(df.filter(items=['Team', 'Points'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some labels\n",
    "print(df.drop(columns=['GF', 'GA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for NA (not available) entries in the DataFrame\n",
    "print(df.isna()) # No NA values\n",
    "print('\\n')\n",
    "\n",
    "# create a pandas Series with a NA value\n",
    "# the Series as W (winnin matches)\n",
    "tmp = pd.Series([np.NaN, 25, 24, 19],  name=\"W\")\n",
    "\n",
    "# concatenate the Series with the DataFrame\n",
    "df = pd.concat([df,tmp], axis = 1)\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# again, check for NA entries\n",
    "print(df.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this week exercises we will use a dataset from the Genomics of Drug Sensitivity in Cancer (GDSC) project (https://www.cancerrxgene.org/). In this study (['Iorio et al., Cell, 2016']()), 265 compounds were tested on 1001 cancer cell lines for which different types of -omics data (RNA expression, DNA methylation, Copy Number Alteration, DNA sequencing) are available. This is a valuable resource to look for biomarkers of drugs sensitivity in order to try to understand why cancer patients responds very differently to cancer drugs and find ways to assign the optimal treatment to each patient.\n",
    "\n",
    "For this exercise we will use a subset of the data, focusing the response to the drug YM155 (Sepantronium bromide) on four cancer types, for a total of 148 cancer cell lines.\n",
    "\n",
    "| ID          | Cancer type                      |\n",
    "|-------------|----------------------------------|\n",
    "|   COAD/READ | Colorectal adenocarcinoma        |\n",
    "|   NB        | Neuroblastoma                    |\n",
    "|   KIRC      | Kidney renal clear cell carcinoma|\n",
    "|   BRCA      | Breast carcinoma                 |\n",
    "\n",
    "We will use the RNA expression data (RMA normalised). Only genes with high variability across cell lines (variance > 5, resulting in 238 genes) have been kept.\n",
    "\n",
    "Drugs have been tested at different concentration, measuring each time the viability of the cells. Drug sensitivity is measured using the natural log of the fitted IC50 metric, which is defined as the half maximal inhibitory concentration. A lower IC50 corresponds to a more sensitive cell line because a lower amount of drug is sufficient to have a strong response, while a higher IC50 corresponds to a more resistant cell line because more drug is needed for killing the cells.\n",
    "\n",
    "Based on the IC50 metric, cells can be classified as sensitive or resistant. The classification is done by computing the $z$-score across all cell lines in the GDSC for each drug, and considering as sensitive the ones with $z$-score < 0 and resistant the ones with $z$-score > 0.\n",
    "\n",
    "The dataset is originally provided as 3 files ([original source](https://www.sciencedirect.com/science/article/pii/S0092867416307462?via%3Dihub)) :\n",
    "\n",
    "`GDSC_RNA_expression.csv`: gene expression matrix with the cell lines in the rows (148) and the genes in the columns (238).\n",
    "\n",
    "`GDSC_drug_response.csv`: vector with the cell lines response to the drug YM155 in terms of log(IC50) and as classification in sensitive or resistant.\n",
    "\n",
    "`GDSC_metadata.csv`: metadata for the 148 cell lines including name, COSMIC ID and tumor type (using the classification from ['The Cancer Genome Atlas TCGA'](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga))\n",
    "\n",
    "For convenience, we provide the data already curated.\n",
    "\n",
    "`RNA_expression_curated.csv`: [148 cell lines , 238 genes]\n",
    "\n",
    "`drug_response_curated.csv`: [148 cell lines , YM155 drug]\n",
    "\n",
    "The curated data cam be read as `pandas` `DataFrame`s in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get to know the data\n",
    "gene_expression = pd.read_csv(\"./data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"./data/drug_response_curated.csv\", sep=',', header=0, index_col=0)\n",
    "\n",
    "print(gene_expression.shape)\n",
    "pp = gene_expression.iloc[0:2,:]\n",
    "print(pp)\n",
    "print('\\n')\n",
    "print(drug_response.values.T)\n",
    "\n",
    "print('\\n')\n",
    "print(drug_response.shape)\n",
    "print(drug_response.iloc[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `DataFrame`s directly as inputs to the the `sklearn` models. The advantage over using `numpy` arrays is that the variable are annotated, i.e. each input and output has a name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "The `scikit-learn` library provides the required tools for linear regression/classification and shrinkage, as well as for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the notation used for the hyperparameters in the `scikit-learn` library is different from the one used in the lecture. More specifically, in the lecture $\\alpha$ is the tunable parameter to select the compromise between Ridge and Lasso. Whereas, `scikit-learn` library refers to `alpha` as the tunable parameter $\\lambda$. Please check the documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Selection of the hyperparameter\n",
    "\n",
    "Implement cross-validation (using `sklearn.grid_search.GridSearchCV`) to select the `alpha` hyperparameter of `sklearn.linear_model.Lasso`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# get values of de pandas Dataframes\n",
    "X = gene_expression.values\n",
    "y = drug_response.values\n",
    "\n",
    "# split data in train and test set\n",
    "# random state ensures that the split is reproducible, so each time you run the train and test set will be the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# standardize X values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "\n",
    "# define parameters for Lasso regression\n",
    "lasso = Lasso(random_state = 0, max_iter = 10000)\n",
    "alphas = np.logspace(-2,1,50)\n",
    "tuned_parameters = [{'alpha':alphas}]\n",
    "n_folds = 5\n",
    "\n",
    "# perform gridsearch on all parameters alpha and fit model\n",
    "grid = GridSearchCV(lasso,tuned_parameters, cv = n_folds)\n",
    "grid.fit(X_train_s,y_train)\n",
    "\n",
    "# get mean test score and standard deviation on all samples\n",
    "scores = grid.cv_results_['mean_test_score']    \n",
    "scores_std = grid.cv_results_['std_test_score']\n",
    "\n",
    "# plot results\n",
    "plt.figure().set_size_inches(7, 5)\n",
    "plt.semilogx(alphas, scores) # plot mean test score for all alphas \n",
    "\n",
    "# plot error lines showing +/- std. errors of the scores\n",
    "std_error = scores_std / np.sqrt(n_folds)\n",
    "plt.semilogx(alphas, scores + std_error, 'b--')\n",
    "plt.semilogx(alphas, scores - std_error, 'b--')\n",
    "\n",
    "plt.ylabel('mean test score +/- std',fontsize=14)\n",
    "plt.xlabel('log(alpha)',fontsize=14)\n",
    "\n",
    "# alpha=0.2 controls the translucency of the fill color\n",
    "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Best parameter: \", grid.best_params_)\n",
    "\n",
    "# refitting on the best parameter alpha\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.fit(X_train_s,y_train).predict(X_test) # perform fitting and predicting in one step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Look at the features selected using the hyperparameter which corresponds to the minimum cross-validation error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with best found value for alpha, so with minimum cross-validation error\n",
    "yr_train = np.ravel(y_train)\n",
    "clf = Lasso(alpha = list(grid.best_params_.values())).fit(X_train_s, yr_train)\n",
    "\n",
    "# the features with the highest coef_ are most important\n",
    "importance = np.abs(clf.coef_)\n",
    "\n",
    "# get the indices of nr_imp most important features\n",
    "nr_imp = 5\n",
    "imp_index = (-importance).argsort() # sort at descending importance, so the first ones have the highest importance\n",
    "i_most_imp_features = imp_index[:nr_imp]\n",
    "\n",
    "# get all feature names\n",
    "feature_names = gene_expression.columns\n",
    "# print feature names of nr_imp features\n",
    "most_imp_features = np.array(feature_names[i_most_imp_features])\n",
    "print('The most relevant features for alpha with the minimum cross-validation error, are: {}'.format(most_imp_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color='#770a0a'>Is the partition in training and validation sets playing a role in the selection of the hyperparameter? How will this affect the selection of the relevant features?</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Use k-fold cross validation to check whether the obtained 'best' value for alpha is independent\n",
    "# of the train/test division, so for different subsets of the data\n",
    "lasso_cv = LassoCV(alphas=alphas, random_state=0, max_iter=10000)\n",
    "nr_k = 7\n",
    "k_fold = KFold(nr_k)\n",
    "\n",
    "alpha_list = []\n",
    "data = [[] for _ in range(nr_k)] \n",
    "nz_coef = [0] * nr_k\n",
    "for k, (train, test) in enumerate(k_fold.split(X, y)):\n",
    "    yr = np.ravel(y) # reshape y from column-vector to 1d array\n",
    "    lasso_cv.fit(X[train], yr[train])\n",
    "    alpha_k = lasso_cv.alpha_\n",
    "    alpha_list.append(alpha_k)\n",
    "    print(\"[fold {0}] alpha: {1:.4f}, score: {2:.4f}\".\n",
    "          format(k, alpha_k, lasso_cv.score(X[test], yr[test])))\n",
    "\n",
    "    clf = Lasso(alpha = alpha_k).fit(X[train], yr[train])\n",
    "    importance = np.abs(clf.coef_)     #get most important features\n",
    "\n",
    "    # get the indices of nr_imp most important features\n",
    "    imp_index = (-importance).argsort() # sort at descending importance, so the first ones have the highest importance\n",
    "    i_most_imp_features = imp_index[:nr_imp]\n",
    "\n",
    "    # get feature names\n",
    "    feature_names = gene_expression.columns\n",
    "    most_imp_features = np.array(feature_names[i_most_imp_features])\n",
    "\n",
    "    # store data for DataFrame\n",
    "    data[k].append(most_imp_features)\n",
    "    nz_coef[k] = np.array(np.nonzero(importance)).shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame\n",
    "data_df = [alpha_list, nz_coef, data]\n",
    "columns = [\"alpha\", \" Nonzero coefficients\", \"Most relevant features\"]\n",
    "\n",
    "second_dataframe = pd.DataFrame(data_df, index=columns)\n",
    "\n",
    "print(second_dataframe.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluding, different subsets of test and train data lead to different values for $\\alpha$ that are optimal and the resulting scores differ a lot respectively. The selected $\\alpha$ can thus not be trusted completely. Subsequently, a different value for hyperparameter $\\alpha$ leads to other features that are selected as most relevant. Since feature ABCB1 is in all folds first in the list of most relevant features, which means that it has the highest coefficient in all folds, it can be said that this feature is most relevant. Additionally, it can be seen in the dataframe that the number of nonzero Lasso regression coefficients is higher for lower $\\alpha$, so the number of coefficients set to zero is higher for higher $\\alpha$. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<p><font color='#770a0a'>Should the value of the intercept also be shrunk to zero with Lasso and Ridge regression? Motivate your answer.</font></p>\n",
    "The idea of Lasso or Ridge regularization is to shrink the regression coefficients by imposing a penalty term on their size. Otherwise, very large values for $\\beta$ that will be multiplied with the feature values are possibly chosen which leads to overfitting. For $\\beta_0$, it is not possible to have an extraordinary large value because then, the model does not fit the data anymore. It is thus not necessary to also shrunk the value of the intercept to zero.\n",
    "\n",
    "\n",
    "## Bias-variance \n",
    "\n",
    "Show the effect of the regularization on the parameter estimates in terms of bias and variance. For this you can repeat the optimization 100 times using bootstrap and visualise the profile of the Lasso regression coefficient over a grid of the hyperparameter, optionally including the variability as error bars.\n",
    "\n",
    "<p><font color='#770a0a'>Based on the visual analysis of the plot, what are your observation on bias and variance in relation to model complexity? Motivate your answer.</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat optimization M times using k-fold cross validation (bootstrap)\n",
    "# feature selection procedure is repeated M times, using every time a different bootstrapped dataset\n",
    "M = 100\n",
    "k_fold = KFold(M)\n",
    "\n",
    "#choose a grid of lambda\n",
    "lambdas = np.logspace(-2,1,M)\n",
    "Coefs = []\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X, y)): #enumerate()function assigns an index to each item in an iterable object that can be used to reference the item later.\n",
    "    yr = np.ravel(y) # reshape y from column-vector to 1d array\n",
    "        \n",
    "    clf = Lasso(alpha = lambdas[k]).fit(X[train], yr[train])\n",
    "    importance = np.abs(clf.coef_)\n",
    "        \n",
    "    # to follow the proces / know how far it is:\n",
    "    print(\"[fold {}] alpha: {}\".format(k, lambdas[k]))\n",
    "    Coefs.append(clf.coef_)\n",
    "    #print(np.array(np.nonzero(importance)))\n",
    "    #print(importance[np.array(np.nonzero(importance))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create plot\n",
    "\n",
    "plt.figure().set_size_inches(18, 6)\n",
    "plt.semilogx(lambdas, Coefs) \n",
    "plt.xlabel('log(alpha)',fontsize=14)\n",
    "plt.ylabel('coefficients',fontsize=14)\n",
    "plt.title('Lasso coefficients as a function of the hyperparameter',fontsize=15)\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step was to look at the bias and variance of the model. This was supposed to be done by repeating the optimalization of the model by using bootstrap. Unfortunatly this did not work and we couldn't fit the model using bootstrap.\n",
    "The random selection went wrong when trying to select a subset of the training data it kept saying that the dimensions were different for the rest of the code so it wouldn't run. We tried to resolve this error but unfortunatly we couldn't do it in the time that was left for the project.\n",
    "The following steps would have been the computation of the mean, variance and standard deviation so it could be plotted for all features with errorbars. And then we would have been able to say something about the bias and the variance of the model.\n",
    "What we expected was that when the lambda increased the variance would decrease since you use less coefficients for estimation. The bias on the other hand would increase when the lambda would increase since you only take a few features into account and the error you make is getting larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "<p><font color='#770a0a'>Write the expression of the objective function for the penalized logistic regression with $L_1$ and $L_2$ regularisation (as in Elastic net).</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer***\n",
    "\n",
    "<br>\n",
    "$L_1$ and $L_2$ regularisation (as in Elastic net) provides a compromise between Rigde and Lasso. This penalty has the form: \n",
    "\n",
    "$\\large\\lambda\\sum\\limits_{j=1}^{P} (\\alpha\\beta_j^2 + (1 - \\alpha)|\\beta_j|))$\n",
    "\n",
    "The second term of the sum encourages highly correlated features to be averaged, while the first term encourages a sparse solution in the coefficients of these averaged features. \n",
    "\n",
    "<br>\n",
    "Adding this penalty to the loss function of logistic regression gives the function for penalized logistic regression with $L_1$ and $L_2$ regularisation\n",
    "\n",
    "$max(\\sum\\limits_{i=1}^{n} (y_i - \\sum\\limits_{j=i}^{p}(x_{ij}\\beta_j)^2)) + \\lambda\\sum\\limits_{j=1}^{P} (\\alpha\\beta_j^2 + (1 - \\alpha)|\\beta_j|)) $\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
